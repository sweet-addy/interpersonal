{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "4_creating_traits_databases.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPllV0WVQssF6DRTVRlPXI5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/waifuai/interpersonal/blob/master/tutorials/4_creating_traits_databases.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TMdKDlMIbjC1",
        "colab_type": "text"
      },
      "source": [
        "## Creating Traits Databases\n",
        "\n",
        "The Traits databases are the core of the program. You can get large precomputed traits databases from our [releases on GitHub](https://github.com/waifuai/interpersonal/releases) or [Kaggle](https://www.kaggle.com/waifuai/interpersonal-traits).\n",
        "To create the traits databases (for friendliness and dominance) we need to download the required files: Google News vectors and Brown Corpus."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJoi0o0kyh_T",
        "colab_type": "text"
      },
      "source": [
        "Start by installing the library from pip. We use version number here to ensure that the documentation will work in the future."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gn67Yxc4g1AZ",
        "colab_type": "code",
        "outputId": "e30f75ec-04f5-4bc2-c7ac-6ca6b542c8fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "!pip install interpersonal==0.0.1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting interpersonal==0.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/be/6a/4b907680f76484b29494aa5da47c7c64fcd21c0edf658445dda097d12c84/interpersonal-0.0.1-py3-none-any.whl\n",
            "Installing collected packages: interpersonal\n",
            "Successfully installed interpersonal-0.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ThksPUcwZopE",
        "colab_type": "code",
        "outputId": "25dc0918-6982-4dc8-c985-10af82bf3d73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "!echo \"Downloading GoogleNews-vectors (1.57 GB)\"\n",
        "!link=\"https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\";wget -c $link 2>/dev/null || curl -L -O -C - $link || curl -L -O $link\n",
        "!du -h /content/GoogleNews-vectors-negative300.bin.gz\n",
        "!echo \"Downloading Brown Corpus (3.3 MB)\"\n",
        "!link=\"https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/packages/corpora/brown.zip\";wget -c $link 2>/dev/null || curl -L -O -C - $link || curl -L -O $link\n",
        "!du -h /content/brown.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading GoogleNews-vectors (1.57 GB)\n",
            "1.6G\t/content/GoogleNews-vectors-negative300.bin.gz\n",
            "Downloading Brown Corpus (3.3 MB)\n",
            "3.2M\t/content/brown.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adfvzYsvl2Gl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "Library for the functions used in populate_traits.py\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "def is_adjective(word, adjectives):\n",
        "    \"\"\"\n",
        "    Check whether the given word is an adjective or not\n",
        "    :param word: the input word\n",
        "    :param adjectives: list of all adjectives in the English language\n",
        "    :return: True if the word is an adjective, False otherwise\n",
        "    \"\"\"\n",
        "    if word in adjectives:\n",
        "        return True\n",
        "    else:\n",
        "        return False\n",
        "\n",
        "\n",
        "def filter_adjectives(a_list, adjectives):\n",
        "    \"\"\"\n",
        "    Filter the list of words to find the adjectives in it\n",
        "    :param a_list: A list of words\n",
        "    :param adjectives: The list of adjectives\n",
        "    :return: A list of all adjectives that were in the input list\n",
        "    \"\"\"\n",
        "    found = []\n",
        "    i = 0\n",
        "    while i < len(a_list):\n",
        "        if is_adjective(a_list[i][0], adjectives):\n",
        "            found.append(a_list[i])\n",
        "        i += 1\n",
        "    return found\n",
        "\n",
        "\n",
        "def scale_min_max(x, xmin, xmax, ymin, ymax):\n",
        "    \"\"\"\n",
        "    scales input into integer output range\n",
        "    :param x: the input value to transform\n",
        "    :param xmin: the minimum input range\n",
        "    :param xmax: the maximum input range\n",
        "    :param ymin: the minimum output range\n",
        "    :param ymax: the maximum output range\n",
        "    :return: the scaled output value\n",
        "    \"\"\"\n",
        "    y = (x - xmin) / (xmax - xmin)\n",
        "    y *= (ymax - ymin)\n",
        "    y += ymin\n",
        "    y = int(y)\n",
        "    return y\n",
        "\n",
        "\n",
        "def scale_my_list(list, positivity):\n",
        "    \"\"\"\n",
        "    Scale a list\n",
        "    Example input :\n",
        "        [('warm_hearted', 0.43241143226623535),\n",
        "        ('playful', 0.3962867259979248),...\n",
        "    Example output:\n",
        "        [['warm_hearted', 11],\n",
        "        ['playful', 7]\n",
        "    :param list: the list to scale\n",
        "    :param positivity: True if friendliness or dominance,\n",
        "    False otherwise\n",
        "    :return: the scaled list\n",
        "    \"\"\"\n",
        "    if positivity:\n",
        "        multiplier = 1\n",
        "    else:\n",
        "        multiplier = -1\n",
        "    i = 0\n",
        "    min = 1\n",
        "    while i < len(list):\n",
        "        if list[i][1] < min:\n",
        "            min = list[i][1]\n",
        "        i += 1\n",
        "    i = 0\n",
        "    max = 0\n",
        "    while i < len(list):\n",
        "        if list[i][1] > max:\n",
        "            max = list[i][1]\n",
        "        i += 1\n",
        "    i = 0\n",
        "    list2 = []\n",
        "    while i < len(list):\n",
        "        new = [list[i][0],\n",
        "               multiplier * scale_min_max(list[i][1], min, max, 1, 10)]\n",
        "        list2.append(new)\n",
        "        i += 1\n",
        "    return list2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6UO8F-JSnUjx",
        "colab_type": "code",
        "outputId": "48a44a90-fd38-48bc-c888-e28a5fe56b99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "from gensim.models import KeyedVectors\n",
        "\n",
        "print(\"Loading GoogleNews-vectors into word2vec (~30 seconds)\")\n",
        "model = KeyedVectors.load_word2vec_format(\n",
        "    'GoogleNews-vectors-negative300.bin.gz',\n",
        "    binary=True,\n",
        "    limit=500000\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading GoogleNews-vectors into word2vec (~30 seconds)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QNv53danl-lj",
        "colab_type": "code",
        "outputId": "f53b1465-d07b-47f8-e6e9-2d5d9bd6d7b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        }
      },
      "source": [
        "\"\"\"\n",
        "This script does all the heavy-lifting of setting up the\n",
        "    initial databases...\n",
        "topn ~ limit/5 seems a good number to ensure\n",
        "    the combination of having enough traits\n",
        "    yet avoiding matches that are completely irrelevant\n",
        "\"\"\"\n",
        "\n",
        "import nltk\n",
        "import zipfile\n",
        "from nltk.corpus import brown\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "from interpersonal.classes.trait_dao import TraitDao\n",
        "\n",
        "TraitDao.create_tables()\n",
        "TraitDao.empty_tables()\n",
        "\n",
        "# using the regular download can result in certificate problems\n",
        "# which are hard to resolve without root access to computer\n",
        "# but if you have root access to computers, this is the simplest way to\n",
        "# download the brown corpora:\n",
        "nltk.download('brown')\n",
        "\n",
        "# print(\"Extracting brown corpora to directory\")\n",
        "# zip_ref = zipfile.ZipFile('brown.zip', 'r')\n",
        "# # if nltk.data.path[0] fails, just try [1],[2],... and so on\n",
        "# # on our system we had about 10 alternative paths, eg. [0]~[9]\n",
        "# # you need write permissions to the path you choose\n",
        "# zip_ref.extractall(nltk.data.path[0])\n",
        "# zip_ref.close()\n",
        "\n",
        "\n",
        "\n",
        "print(\"Extracting words from word2vec model\")\n",
        "friendliness = model.most_similar(\n",
        "    positive=['friendly', 'affectionate', 'loving', 'kind'],\n",
        "    negative=['hostile', 'hurtful', 'unfriendly', 'mean'],\n",
        "    topn=100000\n",
        ")\n",
        "unfriendliness = model.most_similar(\n",
        "    positive=['hostile', 'hurtful', 'unfriendly', 'mean'],\n",
        "    negative=['friendly', 'affectionate', 'loving', 'kind'],\n",
        "    topn=100000\n",
        ")\n",
        "dominance = model.most_similar(\n",
        "    positive=['dominant', 'assertive', 'capable', 'important'],\n",
        "    negative=['submissive', 'apologetic', 'meek', 'passive'],\n",
        "    topn=100000\n",
        ")\n",
        "undominance = model.most_similar(\n",
        "    positive=['submissive', 'apologetic', 'meek', 'passive'],\n",
        "    negative=['dominant', 'assertive', 'capable', 'important'],\n",
        "    topn=100000\n",
        ")\n",
        "\n",
        "# set of over 8000 adjectives\n",
        "adjectives = {word for word, pos in brown.tagged_words()\n",
        "              if pos.startswith('JJ')}\n",
        "\n",
        "print(\"Filtering for adjectives from extracted words\")\n",
        "friendliness = filter_adjectives(friendliness, adjectives)\n",
        "unfriendliness = filter_adjectives(unfriendliness, adjectives)\n",
        "dominance = filter_adjectives(dominance, adjectives)\n",
        "undominance = filter_adjectives(undominance, adjectives)\n",
        "\n",
        "print(\"Scaling the list to fit the range (0,10) or (-10,0)\")\n",
        "friendliness = scale_my_list(friendliness, True)\n",
        "unfriendliness = scale_my_list(unfriendliness, False)\n",
        "dominance = scale_my_list(dominance, True)\n",
        "undominance = scale_my_list(undominance, False)\n",
        "\n",
        "print(\"Adding traits to database:\")\n",
        "print(\"- 1/4\")\n",
        "for trait in tqdm(friendliness):\n",
        "    TraitDao.add_friendliness_trait(trait[0], trait[1])\n",
        "print(\"- 2/4\")\n",
        "for trait in tqdm(unfriendliness):\n",
        "    TraitDao.add_friendliness_trait(trait[0], trait[1])\n",
        "print(\"- 3/4\")\n",
        "for trait in tqdm(dominance):\n",
        "    TraitDao.add_dominance_trait(trait[0], trait[1])\n",
        "print(\"- 4/4\")\n",
        "for trait in tqdm(undominance):\n",
        "    TraitDao.add_dominance_trait(trait[0], trait[1])\n",
        "\n",
        "print(\"traits.db is ready!\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n",
            "Extracting words from word2vec model\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Filtering for adjectives from extracted words\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 6/1738 [00:00<00:30, 56.99it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Scaling the list to fit the range (0,10) or (-10,0)\n",
            "Adding traits to database:\n",
            "- 1/4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1738/1738 [00:14<00:00, 117.04it/s]\n",
            "  1%|          | 11/1503 [00:00<00:13, 109.78it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "- 2/4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1503/1503 [00:13<00:00, 115.49it/s]\n",
            "  1%|          | 12/1261 [00:00<00:10, 119.03it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "- 3/4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1261/1261 [00:10<00:00, 116.11it/s]\n",
            "  1%|          | 12/2074 [00:00<00:17, 118.37it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "- 4/4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2074/2074 [00:23<00:00, 88.58it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "traits.db is ready!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EtAfCKO9mgHq",
        "colab_type": "code",
        "outputId": "b0b817b5-ce17-4209-b201-869255b81c7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!du -h traits.db"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "128K\ttraits.db\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}